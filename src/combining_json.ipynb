{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf1560ef-c2d6-417e-bcb8-e30326d42bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 1197 articles into: Final_output_files/Json_files/Guardian/Education/education.json\n"
     ]
    }
   ],
   "source": [
    "# Guaridan /Education\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Folder where your 5 files are\n",
    "output_dir = \"Final_output_files/Json_files/Guardian/Education\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List your 5 education-related files exactly as they appear\n",
    "education_files = [\n",
    "    \"education_inequality_articles.json\",\n",
    "    \"remote_learning_articles.json\",\n",
    "    \"diversity_education_articles.json\",\n",
    "    \"school_funding_articles.json\",\n",
    "    \"student_loan_debt_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles\n",
    "for filename in education_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"Guardian\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save final combined file\n",
    "output_file = os.path.join(output_dir, \"education.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cae0501-7fd5-4151-b045-1fdc3b94497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 1653 articles into: Final_output_files/Json_files/Guardian/Politics/politics.json\n"
     ]
    }
   ],
   "source": [
    "# Guaridan /Politics\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Where your raw files are\n",
    "output_dir = \"Final_output_files/Json_files/Guardian/Politics\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List your Guardian politics files\n",
    "politics_files = [\n",
    "    \"partisan_divide_articles.json\",\n",
    "    \"foreign_policy_articles.json\",\n",
    "    \"elections_articles.json\",\n",
    "    \"immigration_policy_articles.json\",\n",
    "    \"education_policy_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles under politics\n",
    "for filename in politics_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"Guardian\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save the final combined JSON\n",
    "output_file = os.path.join(output_dir, \"politics.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5027cc23-42d5-4c75-9505-9133a6118f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 1256 articles into: Final_output_files/Json_files/Guardian/Environment/environment.json\n"
     ]
    }
   ],
   "source": [
    "# ENVIRONMENT \n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Location of your downloaded files\n",
    "output_dir = \"Final_output_files/Json_files/Guardian/Environment\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of your Guardian environment issue files\n",
    "environment_files = [\n",
    "    \"climate_change_articles.json\",\n",
    "    \"green_tech_articles.json\",\n",
    "    \"carbon_emission_articles.json\",\n",
    "    \"recycling_articles.json\",\n",
    "    \"sustainability_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles under environment\n",
    "for filename in environment_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"Guardian\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save the final combined file\n",
    "output_file = os.path.join(output_dir, \"environment.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4681f7a0-7b7e-44a4-a1a7-89a7e32054ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 138 articles into: Final_output_files/Json_files/NewsAPI/Education/education.json\n"
     ]
    }
   ],
   "source": [
    "#newsapi- education \n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Location of raw files\n",
    "output_dir = \"Final_output_files/Json_files/NewsAPI/Education\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of your NewsAPI education issue files\n",
    "education_files = [\n",
    "    \"education_inequality_articles.json\",\n",
    "    \"remote_learning_articles.json\",\n",
    "    \"diversity_education_articles.json\",\n",
    "    \"school_funding_articles.json\",\n",
    "    \"student_loan_debt_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles\n",
    "for filename in education_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"NewsAPI\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save final combined file\n",
    "output_file = os.path.join(output_dir, \"education.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06cf56de-b592-4ccd-bb8d-0150d16d1bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 408 articles into: Final_output_files/Json_files/NewsAPI/Politics/politics.json\n"
     ]
    }
   ],
   "source": [
    "#newsApi- politics \n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Folder where the raw files are\n",
    "output_dir = \"Final_output_files/Json_files/NewsAPI/Politics\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of your NewsAPI politics issue files\n",
    "politics_files = [\n",
    "    \"partisan_divide_articles.json\",\n",
    "    \"foreign_policy_articles.json\",\n",
    "    \"elections_articles.json\",\n",
    "    \"immigration_policy_articles.json\",\n",
    "    \"education_policy_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles under politics\n",
    "for filename in politics_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"NewsAPI\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save the final combined file\n",
    "output_file = os.path.join(output_dir, \"politics.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "742bc02e-380b-4a4c-b3e9-3ae52b052c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 73 articles into: Final_output_files/Json_files/NewsAPI/Environment/environment.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Folder where your raw files are\n",
    "output_dir = \"Final_output_files/Json_files/NewsAPI/Environment\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of your NewsAPI environment issue files\n",
    "environment_files = [\n",
    "    \"climate_change_articles.json\",\n",
    "    \"recycling_articles.json\",\n",
    "    \"carbon_emission_articles.json\",\n",
    "    \"green_tech_articles.json\",\n",
    "    \"air_pollution_articles.json\",\n",
    "    \"sustainability_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles under environment\n",
    "for filename in environment_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"NewsAPI\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save the final combined file\n",
    "output_file = os.path.join(output_dir, \"environment.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c4e8a22-76ef-473d-8817-7ad384e3fa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 262 articles into: Final_output_files/Json_files/Nytimes/Education/education.json\n"
     ]
    }
   ],
   "source": [
    "#Nytimes- education\n",
    "# Guaridan /Education\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Folder where your 5 files are\n",
    "output_dir = \"Final_output_files/Json_files/Nytimes/Education\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List your 5 education-related files exactly as they appear\n",
    "education_files = [\n",
    "    \"education_inequality_articles.json\",\n",
    "    \"remote_learning_articles.json\",\n",
    "    \"diversity_education_articles.json\",\n",
    "    \"school_funding_articles.json\",\n",
    "    \"student_loan_debt_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles\n",
    "for filename in education_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"Nytimes\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save final combined file\n",
    "output_file = os.path.join(output_dir, \"education.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f78d6567-8525-4654-80a7-87f63d572b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 500 articles into: Final_output_files/Json_files/Nytimes/Politics/politics.json\n"
     ]
    }
   ],
   "source": [
    "#Nytimes - politics\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Where your raw files are\n",
    "output_dir = \"Final_output_files/Json_files/Nytimes/Politics\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List your Guardian politics files\n",
    "politics_files = [\n",
    "    \"partisan_articles.json\",\n",
    "    \"foreign_articles.json\",\n",
    "    \"elections_articles.json\",\n",
    "    \"immigration_articles.json\",\n",
    "    \"education_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles under politics\n",
    "for filename in politics_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"Nytimes\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save the final combined JSON\n",
    "output_file = os.path.join(output_dir, \"politics.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1771ccb7-1fb8-4e82-8c4c-e9261021c7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Combined 293 articles into: Final_output_files/Json_files/Nytimes/Environment/environment.json\n"
     ]
    }
   ],
   "source": [
    "#Nytimes - environment \n",
    "import os\n",
    "import json\n",
    "\n",
    "# === PATHS ===\n",
    "input_dir = os.path.expanduser(\"~/Downloads\")  # Location of your downloaded files\n",
    "output_dir = \"Final_output_files/Json_files/Nytimes/Environment\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of your Guardian environment issue files\n",
    "environment_files = [\n",
    "    \"climate_change_articles.json\",\n",
    "    \"green_tech_articles.json\",\n",
    "    \"carbon_emissions_articles.json\",\n",
    "    \"recycling_articles.json\",\n",
    "    \"sustainability_articles.json\"\n",
    "]\n",
    "\n",
    "combined_articles = []\n",
    "\n",
    "# Combine all articles under environment\n",
    "for filename in environment_files:\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"⚠️ File not found: {filename} — skipping\")\n",
    "        continue\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for article in data:\n",
    "                article[\"issue\"] = filename.replace(\"_articles.json\", \"\").replace(\"_\", \" \")\n",
    "                article[\"source\"] = \"Nytimes\"\n",
    "            combined_articles.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "\n",
    "# Save the final combined file\n",
    "output_file = os.path.join(output_dir, \"environment.json\")\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined_articles, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n✅ Combined {len(combined_articles)} articles into: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfee75e-9c96-4f99-8a8b-0e1ae74216fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
